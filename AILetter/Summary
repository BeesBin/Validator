
[1편] 인공지능 첫걸음														 
1 인공지능에 대한 오해와 진실               
1.1 인공지능은 로봇이다?                 
	'인공지능=로봇'이란 공식이 항상 성립하지는 않습니다.
	인공지능이란 하나의 소프트웨어 프로그램에 지나지 않습니다.

1.2 인공지능은 스스로 똑똑해질 수 있다?
	스스로 학습해서 진화하는 것 X
	인공지능 대부분 지도학습(Supervised Learning), 사람이 정답을 알려줘야함
	빅데이터 붐 이후로 학습할 데이터가 많아졌다 O
	사람이 인공지능 구조를 하나씩 설계/최적화 기법 적용 실험 해야 성능 더 좋다

1.3 인공지능도 감정이 있다?
	인공지능이 감정을 가질 일은 없습니다. '감정을 가지는 척'하도록 프로그래밍할 수는 O
	인공지능의 학습 및 추론이란 데이터를 벡터나 매트릭스 형태의 텐서(tensor)로 만들어 복잡 다양한 행렬 연산을 하는 것


2 인공지능(Artificial Intelligence;AI)이란           
2.1 강 인공지능, 약 인공지능                 
2.1.1 강 인공지능 (Strong AI, General AI)
	감정적으로 풍부한/ 만능 가사 비서/ 위협적인 형태가 될 수도 있는 영화상의 인공지능
	스스로 판단/ 결정/ 유연한 대처/ 대화/ 범용성 '범 인공지능'

2.1.2 약 인공지능 (Weak AI, Narrow AI)            
	우리의 일상생활에서 만나는 모든 인공지능은 '약 인공지능'
	제한된 환경에서 구체적인 특정 업무를 수행하는 데 있어서 사람과 비슷한, 또는 사람 이상의 성능을낼 수 있는 인공지능
	구글 딥마인드의 알파고, IBM의 암 진단 인공지능
	
	아직까지의 인공지능은 '약 인공지능'에 한정적, '전문성(특화성)'은 있지만 다양한 상황 대처의 '범용성'은 떨어지죠.
	약 인공지능 : 눈부신 발전, 강 인공지능 : 아직

2.1.3 범용성과 전문성
	범용성과 전문성의 구별이 절대적이지 않고 오히려 정도의 차이임
	범용적이라고 해서 무엇이든지 다 할 수 있는 것도 아니고, 전문적이라고 해서 단 하나의 작업만 할 수 있는 것도 아닙니다.


2.2 넓은 의미의 AI, 좁은 의미의 AI
	넓은 의미에서 보자면 사람의 반복적인 노동을 줄여줄 수 있도록 기계로 자동화 할 수 있는 것들은 다 인공지능
	좁은 의미의 인공지능, 즉 딥러닝 기반의 인공지능(Deep Learning based AI)

2.2.1 특징(feature) 추출과 의사 결정     
	기계자동화(규칙 기반의 AI)/ 머신러닝/ 딥러닝 구분
	1. 특징 추출 - 문제 해결을 위해 어떤 정보가 유용할 지, 중요한 것을 꺼내는 과정입니다.
	2. 판단 방식 - 추출한 중요 특징으로부터 인식을 하거나 판단을 모델을 만드는 단계입니다.
	규칙 기반 프로그래밍에서 딥러닝으로 갈수록 사람의 개입이 줄어든다
	딥러닝만이 스마트한 인공지능이고, 규칙 기반 프로그래밍이 쓸모없는 기술이란 말은 아닙니다. 
	구현 편의성, 복잡도, 적용 상황에 따라 각 방식의 장단점이 있음

																			 
[2편] 기계도 사람처럼 판단할 수 있을까?									  
1 머신러닝과 딥러닝                    
1.1 머신러닝이 다루는 정형 데이터(structured data)
	머신러닝 (Machine Learning) = 정형 데이터 (Structured Data)
	- 정형 데이터 : 관계형 DB, 엑셀, CSV : 안정성 높음, 체계적, 구조 고정, 유연x, 사람이 정제하고 정리한 데이터 
	- 머신러닝 기반 기술 = 빅데이터 분석 기법, 통계분석 툴 (R, SAS, SPSS) 사용
 		1. 선형/로지스틱 회귀 분석 (실수 값 예측)
 		2. 범주형 분석 (의사 결정 나무)
 		3. 시계열 분석 (ARMA, ARIMA 모형) 등

1.2 딥러닝이 다루는 비정형 데이터(unstructured data) 
	딥러닝 (Deep Learning) = 비정형 데이터 (unstructured data)
비정형 데이터 : 사람 양식 정리x, 다양한 형식o, 원자료(Raw data)
다양한 텍스트 데이터 예 : 웹 페이지, 상품 리뷰, SNS 글, 기업용 문서, 뉴스기사 등 (구어체)
다양한 음성 데이터 예 : 전화 통화, 발화, 동영상 내 음성, 기계음, 신호 등 (의성어)
다양한 이미지 데이터 예 : 흑백 사진, 컬러 사진, 그림, 손글씨 이미지, 얼굴 이미지 등
다양한 동영상 데이터 예 : 유튜브, 영화, CCTV 등	

정형 데이터도 그 수가 꾸준히 늘어나는 추세지만, 비정형 데이터는 기하급수적으로 빠르게 생산
2030년이 되면 전체 데이터의 약 90% 이상이 비정형 데이터가 될것

2 긍정 리뷰와 부정 리뷰 자동 분류하기              
2.1 특징 및 분류기준
	[레거시 방식] 데이터 수집 및 분류 기준 : 기계에게 우리가 알고 있는 긍정, 부정문에 대한 지식을 프로그래밍하여 알려줌
	① 수집 조건 : 조건에 맞는 데이터, 분석 대상 필터링
	② 분류 조건 : 사람의 지식을 프로그래밍을 통해 기계에 알림 

2.2 예외 CASE
	 [레거시 방식] 예외 Case 발생함
① 수집 조건 키워드
   : 맥락상 상관 없는 글들이 걸리기도 하고, 수집되어야 할 글이 걸리지 않기도 함

② 긍/부정 분석
   : '안', '못' 같은 부정어
     케이스 정의가 쉽지 않은, 신조어/유행어
     오타, 띄어쓰기를 지키지 않은 경우 등 '맞춤법 오류'

- 사람과 달리, 기계는 전체 맥락과 뉘앙스를 고려하지 않음. 일부 키워드로만  판단함
- 새로운 예외 발생 시, 규칙 코드를 계속 추가 하여야 함

2.3 모라벡의 역설(Moravec's Paradox)
  사람에게 쉬운 것이 기계에게는 어렵다.
  기계에게 쉬운 것은 사람에게 어렵다.
- 복잡한 계산, 수식 증명, 수치 예측, 번역 : 기계가 잘함 : 연산이 필요한 영역 : 동물의 진화과정 중 겪지 못한 일
- 시각, 움직임, 직감, 맥락 이해 : 사람이 잘함 : 동물이 생각하지 않고 잘 하는 영역 : 동물의 진화과정에서 수억년동안 최적화 됨 

2.4 사람처럼 사고하기
	 : 사람은 다양한 예외 상황, 키워드가 몇 개 없어도, 척 보고 잘 구별한다.

  사람 : 사전적 정의나 규칙을 통해서 X
         사례를 통해 자연적으로 개념을 습득한다 O
         귀납적으로 긍/부정 표현에 대한 말로는 구체화하기 어려운 특징/정보들 습득 O
  = 기계도 수많은 있는 그대로의 사례들 (raw data)로 부터 구별하여, 말로는 할 수 없는 사전적 정의가 아닌 특징을 배우게 하면, 다양한 예외에도 잘 대처할 수 있을 것임 = 비정형 데이터를 딥러닝 기반 AI 개념

3 인공신경망(Artificial Neural Network)              
	딥러닝 방식
	1. 사람의 사고방식을 기계학습에 적용
	2. 컴퓨터공학 & 신경과학 콜라보
	3. 딥러닝 기본 구조 : 인공 신경망

	4. 인간의 지식을 프로그래밍 하여 기계에 전달 필요X 
		다양한 사례를 보여주면, 최적의 연산 모델 찾음O
		★데이터를 통해 자동으로 필요한 (말로 표현 할 수 없는) 특징을 찾아내고 분류 수행

	5. 기계 자동화의 패러다임 변화
		인간이 알고 있는 지식(규칙)을 기계에 전수X
		인간이 사고하는 방식 그 자체를 기계에게 알려주고 데이터를 제공O

3.1 인공뉴런(Artificial Neuron)
사람의 신경계 vs 인공신경망

1. 사람의 신경계
	: 사람은 뉴런으로 데이터를 받아들이고, 처리하고, 전달하여 정보를 얻고 생각을 한다.
  - 신경세포, 뉴런 (Neuron) 
    : 세포의 한 쪽 (수상돌기)에서 받아들인 전기 자극 정보를 여러 처리 후, 다른 쪽 끝(축삭 말단)에서 다음 뉴런으로 전달
  - 신경계
    : 뉴런이 여럿 연결되어 구성

2. 인공 신경망 (Artificial Neural Network)
	: 생물학적 뉴런의 모양을 그대로 본따 인공적으로 뉴런을 만들고, 다양한 방식으로 여러 층 연결하여 데이터를 흘림
  - 인공 뉴런 (Artificial Neuron)
	: 이전의 뉴런이 넘겨준 데이터를 받아들여, 가중합 연산 및 비선형함수 적용한 정보가공 후, 다음에 이어지는 인공 뉴런으로 데이터를 전달
 - 인공 신경망 (Artificial Neural Network)
	: 인공 뉴런을 다양한 방식으로 여러 층 쌓아 연결하여 구성    

3.2 딥러닝이 유행하게 된 배경
	1957년 코넬 항공 연구소/프랑크 로젠블라트 
	이미 인공지능 발전은 인공 뉴런 모태인 '퍼셉트론 (Perceptron)'을 고안
	당시 시대의 여러 한계들이 받쳐주지 못하여 길고 긴 암흑기를 맞이하고, 최근 다시 유행 한 것

	인공지능의 개념, 딥러닝의 개념은 최근 새로 만들어진 것 X
	이미 고안되었던 것임 O

	딥러닝 적용 제약조건 & 해결 배경
	1. 양질의 데이터 다량 확보해야만 높은 모델 성능을 얻음
    데이터로부터 특징을 스스로 찾기 때문임
     => 빅데이터 붐이 일어, 기업들 양질의 데이터 다량 확보 총력, 그 중 비정형 데이터의 비중 증가

	2. 높은 스펙의 하드웨어가 필요
    인공신경망의 구조가 매우 복잡하며 이를 통해 연산을 수행하고 최적화를 해야 함, 규모가 어마어마함
     => 하드웨어 눈부신 발전, 더 많은 데이터 저장 & 처리 속도 빨라짐
    GPU 10배 속도 TPU (Tensor Processing Unit) 칩, 클라우드 서비스, 분산 저장 처리의 빅데이터 처리 기술 발달
	딥러닝의 성능 발전, 앞으로 기대 Ok
																	 
[3편] 시각을 얻은 인공지능												   
1 이미지를 인식하는 인공지능                 
1.1 인공신경망 연산                    
1.2 기계가 이미지를 인식하는 방법              
2 Convolutional Neural Network(CNN)             
2.1 특징 추출(Feature Extraction)              
2.2 태스크 수행                    
2.2.1 Classification                   
2.2.2 Detection                      
2.2.3 Segmentation                   
3 ImageNet Large Scale Visual Recognition Competition        
																			 
[4편] 언어를 이해하는 인공지능												 
1 언어를 인식하는 인공지능                
1.1 자연어이해(NLU; Natural Language Understanding)        
1.1.1 자연(Natural)                    
1.1.2 언어(Language)                  
1.1.3 이해(Understanding)                 
2 기계에게 사람의 언어를 인식시키려면?             
2.1 Tokenizing(Parsing)                 
2.2 워드임베딩(word embedding)               
2.2.1 원-핫 인코딩(One-hot Encoding)               
2.2.2 CBOW와 SKIPGRAM                  
3 다양한 자연어이해 과제들                
3.1 문장/문서 분류(Sentence/Document Classification)         
3.2 Sequence-to-Sequence                   
3.3 질의 응답(Question Answering)                
																			 
[5편] 과거의 경험을 통해 현재를 배우는 인공지능							  
1 시간 흐름에 따른 데이터(Sequential data) 처리하기          
2 Recurrent Neural Network(RNN; 순환 신경망)          
2.1 장점                      
2.1.1 RNN은 시간 흐름에 따른 과거 정보를 누적할 수 있다       
2.1.2 RNN은 가변 길이의 데이터를 처리할 수 있다         
2.1.3 RNN은 다양한 구성의 모델을 만들 수 있다          
2.2 단점                      
2.2.1 연산 속도가 느리다                 
2.2.2 학습이 불안정하다                  
2.2.3 실질적으로 과거 정보를 잘 활용할 수 있는 모델이 아니다     
2.3 성능 보완                     
2.3.1 LSTM(Long-short term memory)               
3 활용 사례                      
																			 
[6편] 헛똑똑이 인공지능 제대로 가르치기										 
1 AI Process                       
1.1 Offline Process                   
1.2 Online Process                   
2 오버피팅(Overfitting)과 일반화 성능(Generalization)        
2.1 Training, Validation, Test               
2.1.1 Training set                   
2.1.2 Validation set                  
2.1.3 Test set                     
2.2 학습 곡선(Learning curve) 확인하기            
3 Regularization                    
3.1 데이터 증강(Data Augmentation)              
3.2 Capacity 줄이기                    
3.3 조기 종료(Early stopping)               
3.4 드롭아웃(Dropout)                    
																			 
[7편] 다시쓰고 바꿔쓰자! 인공지능 재활용하기								   
1 쉽지 않은 인공지능 적용하기               
1.1 구체적이지 않으며 불명확한 태스크              
1.2 적은 데이터, 낮은 품질의 데이터              
1.3 다른 도메인 환경                  
2 Transfer Learning : 한번 만든 인공지능 모델 우려먹기       
2.1 Catastrophic forgetting : 치명적인 기억상실!           
2.2 더 나은 Transfer Learning을 위한 방법           
3 Transfer Learning 모델 이용               
3.1 컴퓨터 비전에서의 Transfer Learning            
3.2 자연어 이해(NLU)에서의 Transfer Learning           
																			 
[8편] 준비된 인공지능, Pre-trained AI										 
1 Pre-training: 니가 뭘 요청할지 몰라서 일단 다 공부해놨어       
2 대규모 데이터에 대한 Pre-training              
2.1 시각 데이터에 대한 사전학습                
2.2 언어 데이터에 대한 사전학습                
3 Self-Supervised Learning: 나 혼자 어떻게든 해볼게        
3.1 예: 이미지 데이터를 위한 Self-Supervised Learning        
3.2 예: 텍스트 데이터를 위한 Self-Supervised Learning        
3.3 예: Google BERT(Bidirectional Encoder Representations from Transformers) 
																			 
[9편] 족집게 데이터로 인공지능 학습하기										 
1 데이터의 바다, 정보의 홍수                 
2 Active Learning: 족집게 데이터로 공부하기            
2.1 Active Learning의 절차                 
2.2 Query Strategy: 이 데이터를 제게 가르쳐 주십시오!        
2.2.1 Uncertainty Sampling                
2.2.2 Query by committee                   
																			 
[10편] 뭣이 중한지 알아보는 인공지능										   
1 긴 입력 데이터 처리하기                 
2 어텐션 메커니즘(Attention mechanism)             
2.1 어텐션 스코어(Attention score)               
2.2 컨텍스트 벡터(Context vector)              
3 XAI로서의 어텐션                     
3.1 텍스트에서의 어텐션                  
3.2 이미지에서의 어텐션                  
4 Attention 전성시대, Transformer              
																			 
[11편] 스스로 진화하는 인공지능, AutoML										 
1 사람의 손을 필요로 하는 인공지능              
2 스스로 진화하는 인공지능, AutoML              
2.1 하이퍼파라미터 탐색 자동화               
2.2 아키텍처 탐색 자동화                   
3 AutoML 특징                     
4 AutoML 서비스                    
																			 
[12편] 설명 가능한 인공지능, XAI											   
1 종종 이해할 수 없는 결정을 내리는 AI            
2 설명 가능한 인공지능, XAI(eXplainable Artificial Intelligence)     
2.1 XAI의 필요성                     
3 XAI를 위한 접근법                   
3.1 어텐션 메커니즘(Attention Mechanism)을 활용한 XAI        
3.2 설명하는 법 학습하기(Learn to explain)            